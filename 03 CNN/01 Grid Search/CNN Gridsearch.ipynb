{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dropout\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "train = pd.read_csv(r'C:\\Users\\sdinu\\OneDrive\\Documents\\02 MS BA\\04 Fall 2017\\IDS594 Machine Learning with Python\\02 Project\\01 Dataset\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\sdinu\\OneDrive\\Documents\\02 MS BA\\04 Fall 2017\\IDS594 Machine Learning with Python\\02 Project\\01 Dataset\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path to read train and test image\n",
    "TRAIN_PATH = 'C:/Users/sdinu/OneDrive/Documents/02 MS BA/04 Fall 2017/IDS594 Machine Learning with Python/02 Project/01 Dataset/train_img/'\n",
    "TEST_PATH = 'C:/Users/sdinu/OneDrive/Documents/02 MS BA/04 Fall 2017/IDS594 Machine Learning with Python/02 Project/01 Dataset/test_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to read images as arrays\n",
    "def read_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (128,128)) # you can resize to  (128,128) or (256,256)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2250/2250 [00:52<00:00, 43.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 965/965 [00:10<00:00, 94.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 128, 128, 3)\n",
      "(965, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read images\n",
    "train_data = []\n",
    "test_data = []\n",
    "train_labels = train['label'].values\n",
    "\n",
    "for img in tqdm(train['image_id'].values):\n",
    "    train_data.append(read_image(TRAIN_PATH + '{}.png'.format(img)))\n",
    "\n",
    "train_array = np.asarray(train_data)\n",
    "    \n",
    "for img in tqdm(test['image_id'].values):\n",
    "    test_data.append(read_image(TEST_PATH + '{}.png'.format(img)))\n",
    "\n",
    "test_array = np.asarray(test_data)\n",
    "    \n",
    "train_array = train_array.reshape(train_array.shape[0], 128, 128, 3).astype('float32')\n",
    "test_array = test_array.reshape(test_array.shape[0], 128, 128, 3).astype('float32')\n",
    "\n",
    "train_array /= 255\n",
    "test_array /= 255\n",
    "print(train_array.shape)\n",
    "print(test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target variable - encoding numeric value\n",
    "label_list = train['label'].tolist()\n",
    "Y_train = {k:v for v,k in enumerate(set(label_list))}\n",
    "y_train = [Y_train[k] for k in label_list]\n",
    "\n",
    "label_list = test['label'].tolist()\n",
    "Y_test = {k:v for v,k in enumerate(set(label_list))}\n",
    "y_test = [Y_test[k] for k in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 25\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter tuning - Optimizer selection\n",
    "\n",
    "# Defining model\n",
    "def CNN_optimizer(optimizer='SGD'):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu', kernel_initializer='uniform',\n",
    "                 input_shape=(128, 128, 3)))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='uniform'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\tmodel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(CNN_optimizer, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters - Optimization Algorithms\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(model, param_grid=param_grid, n_jobs=1, \n",
    "                    scoring='neg_log_loss')\n",
    "grid_result = grid.fit(train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -2.932136 using {'optimizer': 'Adagrad'}\n",
      "-3.108464 (0.024585) with: {'optimizer': 'SGD'}\n",
      "-4.161799 (0.200477) with: {'optimizer': 'RMSprop'}\n",
      "-2.932136 (0.071840) with: {'optimizer': 'Adagrad'}\n",
      "-3.164707 (0.322411) with: {'optimizer': 'Adadelta'}\n",
      "-3.975320 (0.175443) with: {'optimizer': 'Adam'}\n",
      "-3.093017 (0.203063) with: {'optimizer': 'Adamax'}\n",
      "-6.275841 (0.733833) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results - Optimization Algorithms\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter tuning - Epoch and Batchsize\n",
    "\n",
    "# Defining model\n",
    "def CNN_epoch_batchsize():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu', kernel_initializer='uniform',\n",
    "                 input_shape=(128, 128, 3)))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='uniform'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\tmodel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(CNN_epoch_batchsize, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters - Epochs and Batch Size\n",
    "\n",
    "batch_size = [64, 128 , 256]\n",
    "epochs = [5, 10, 15]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, \n",
    "                    scoring='neg_log_loss')\n",
    "grid_result = grid.fit(train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -2.822614 using {'batch_size': 256, 'epochs': 15}\n",
      "-12.178999 (12.875563) with: {'batch_size': 64, 'epochs': 5}\n",
      "-12.648912 (13.498463) with: {'batch_size': 64, 'epochs': 10}\n",
      "-12.535687 (13.092475) with: {'batch_size': 64, 'epochs': 15}\n",
      "-3.181633 (0.119573) with: {'batch_size': 128, 'epochs': 5}\n",
      "-2.862587 (0.018580) with: {'batch_size': 128, 'epochs': 10}\n",
      "-3.037257 (0.060851) with: {'batch_size': 128, 'epochs': 15}\n",
      "-3.224295 (0.094919) with: {'batch_size': 256, 'epochs': 5}\n",
      "-3.125799 (0.067949) with: {'batch_size': 256, 'epochs': 10}\n",
      "-2.822614 (0.087138) with: {'batch_size': 256, 'epochs': 15}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results - Epochs and Batch Size\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter tuning - Learning Rate\n",
    "\n",
    "def CNN_learningRate(learn_rate=0.1):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu', kernel_initializer='uniform',\n",
    "                 input_shape=(128, 128, 3)))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='uniform'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\toptimizer = Adagrad(lr=learn_rate)\n",
    "\tmodel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(CNN_learningRate, epochs=15, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters - Learning Rate\n",
    "learn_rate = [0.1, 0.075, 0.005]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, \n",
    "                    scoring='neg_log_loss')\n",
    "grid_result = grid.fit(train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -2.907828 using {'learn_rate': 0.005}\n",
      "-31.944531 (0.207090) with: {'learn_rate': 0.1}\n",
      "-32.236191 (0.075202) with: {'learn_rate': 0.075}\n",
      "-2.907828 (0.099609) with: {'learn_rate': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results - Learning Rate\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter tuning - Kernel Initializer\n",
    "\n",
    "def CNN_kernelinit(init_mode='uniform'):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu', kernel_initializer=init_mode,\n",
    "                 input_shape=(128, 128, 3)))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer=init_mode))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\toptimizer = Adagrad(lr=0.005)\n",
    "\tmodel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(CNN_kernelinit, epochs=15, batch_size=256, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters - Kernel Initializer\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', \n",
    "             'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, \n",
    "                    scoring='neg_log_loss')\n",
    "grid_result = grid.fit(train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -3.184707 using {'init_mode': 'zero'}\n",
      "-32.159438 (0.287183) with: {'init_mode': 'uniform'}\n",
      "-33.019070 (0.533087) with: {'init_mode': 'lecun_uniform'}\n",
      "-32.190140 (0.321264) with: {'init_mode': 'normal'}\n",
      "-3.184707 (0.009047) with: {'init_mode': 'zero'}\n",
      "-32.712059 (0.735226) with: {'init_mode': 'glorot_normal'}\n",
      "-32.282243 (0.362611) with: {'init_mode': 'glorot_uniform'}\n",
      "-32.098036 (0.228718) with: {'init_mode': 'he_normal'}\n",
      "-32.543203 (0.402056) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results - Kernel Initializer\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
